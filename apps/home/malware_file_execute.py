import markov
import markov_frequency
import numpy as np
import os
import matplotlib.pyplot as plt
from scipy import fft
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import transforms
from PIL import Image
import binascii

np.set_printoptions(threshold=np.inf)

class VGG(nn.Module):
    def __init__(self, num_classes=2):
        super(VGG, self).__init__()
        self.features = nn.Sequential(

            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),
            # nn.Dropout(0.2),

            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding = 0),
            # nn.Dropout(0.2),

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding = 0),
            # nn.Dropout(0.2),

            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding = 0),
            # nn.Dropout(0.2),

            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding = 0),
            # nn.Dropout(0.2),

            nn.Conv2d(512, 1024, kernel_size=3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, kernel_size=1, padding=1),
            nn.BatchNorm2d(1024),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2, padding = 0),
            # nn.Dropout(0.2),

            # nn.Conv2d(1024, 1024, kernel_size=3, padding=1),
            # nn.BatchNorm2d(1024),
            # nn.ReLU(inplace=True),
            # nn.Conv2d(1024, 1024, kernel_size=3, padding=1),
            # nn.BatchNorm2d(1024),
            # nn.ReLU(inplace=True),
            # nn.Conv2d(1024, 1024, kernel_size=1, padding=1),
            # nn.BatchNorm2d(1024),
            # nn.ReLU(inplace=True),
            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0),
            # # nn.Dropout(0.2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))
        # num_features = 512 * (256 // 32) * (256 // 32)
        self.classifier = nn.Sequential(
            nn.Linear(1024 * 7 * 7, 1024),  # 壓平後的輸入尺寸為 512x7x7
            nn.ReLU(inplace=True),
            # nn.Dropout(p=0.5),  # 避免過擬合
            nn.Linear(1024, num_classes),  # 輸出類別數,
            nn.Softmax(dim = 1),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = VGG(num_classes=2).to(device)
model.load_state_dict(torch.load("C:/Users/digital/Desktop/malware/malware_analysis1.pt"))

def read_file(path):
    f = open(path, "rb")
    data_in = f.read()
    arr = np.frombuffer(data_in, dtype=np.uint8)

    arr = arr.flatten()
    hex_list = ("{:02X}".format(int(c)) for c in arr)
    # print(hex_list)
    f.close()
    return hex_list
#file_to_markov matrix
def file_to_hex(hex_list):
    buflist = list(hex_list)
    buf = bytearray(int(x, 16) for x in buflist)
    hex_str = buf.hex()
    hex = hex_str

    deci_dict = {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4', '5': '5', '6': '6', '7': '7', '8': '8', '9': '9',
                'a': '10', 'b': '11', 'c': '12', 'd': '13', 'e': '14', 'f': '15', }
    data = []
    for j in hex:
        data.append(int(deci_dict[j]))
    mc = markov.MarkovChain(16, 2)
    mc.fit(data)
    matrix = mc.transition_matrix.todense()
    return matrix

#markov_matrix_to_npy
def markov_to_npy(matrix):
    file = "D:\downloads\malware_file_input"
    output_path = os.path.join(file, "try1.npy")
    np.save(output_path, matrix)
    M = matrix  # 你的 256×256 矩陣，dtype 應為 uint8 或可轉為
    # M_uint8 = (M * 255).astype(np.uint8)  # 如果 M 在 [0,1] 區間，轉成 0–255
    M_min, M_max = M.min(), M.max()
    M_norm = (M - M_min) / (M_max - M_min)
    M_uint8 = (M_norm * 255).astype(np.uint8)

    img = Image.fromarray(M_uint8, mode='L')
    output_path = os.path.join(file, "try1.png")
    img.save(output_path)

def load_markov_matrices2(input_folder):
    dataset = []
    cnt = -1
    for root, dirs, files in os.walk(input_folder):
        cnt2 = 0
        # print('type', root)
        for file in files:
            if file.endswith('.npy'):
                cnt2 += 1
                # print(cnt2)
                matrix_path = os.path.join(root, file)
                matrix = np.load(matrix_path)
                # 假設你想要將類別信息也存儲在 dataset 中
                # 這裡可以根據路徑來確定類別
                # class_label = os.path.basename(os.path.dirname(matrix_path))
                dataset.append((matrix, int(cnt)))
        cnt += 1
    return dataset, 0

# 設定輸入路徑
input_folder = "D:\downloads\malware_file_input"
path = "D:\downloads\CBD111006.doc"
hex_list = read_file(path)
# 讀取 Markov 矩陣
datasets, cnt = load_markov_matrices2(input_folder)
hex = file_to_hex(hex_list)

model.eval()
actual_loader = DataLoader(dataset = datasets, batch_size = 1, shuffle = False)
criterion = nn.CrossEntropyLoss()
with torch.no_grad():
    correct = 0
    total = 0
    for images, label in actual_loader:
        images = images.unsqueeze(1).float()
        output = model(images.to(device))

print(output)

#1.檔案選擇
#2.讀取檔案
#3.轉換成十六進制
#4.轉換成.npy檔
#5.1暫存至資料夾
#5.2模型推論
